{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Deep Zork**\n",
    "***\n",
    "Can a machine learn to play a text-based game?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='zork_box_art.jpg'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Motivation\n",
    "***\n",
    "Advances in machine learning involving reinforcement learning has seen the rise of AIs capable of playing video games and outperforming human players. These include all sorts of games from chess and Go to Atari games. All of these instances involve games in which gameplay is based on visuals. Using convolutional neural networks, machines become quite capable of recognizing patterns in changing pixels on a screen and can react in real-time in order to win. \n",
    "\n",
    "Enter text-based games.\n",
    "\n",
    "Also known as interactive fiction games, text-based games were some of the first ever computer games due to relying solely on text for gameplay and not needing to process graphics. They rely on language parsing text commands given by the player in response to changing descriptions of the player's environment. \n",
    "\n",
    "This presents a whole different type of problem for AIs attempting to play one of these games. In text-based games, reaction time is not a factor. Instead, the player must have an understanding of the language used and to be able to make smart decisions based off of subtle hints in the game's descriptions.\n",
    "\n",
    "For example, if a game tells the player that, to the north lies a monster that will kill the player if they head that direction, the player should know not to go that way.\n",
    "\n",
    "There have been some attempts at teaching machines to play text-based games with a key example being __TextWorld__ by Microsoft with variable success. There is still, however, a long way to go before an interactive fiction AI will perform at the level of AlphaGo or AlphaZero.\n",
    "\n",
    "This project will aide in tackling the issue by focusing on teaching a machine to play one single game - Zork - in hopes that the techniques used can be applied to other games in the future. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About Zork\n",
    "***\n",
    "### History\n",
    "***\n",
    "One of the most classic and well-known text-based game, Zork I (also known as Zork: The Great Underground Empire), was written in the late 1970s. At the time it was well-revered for its compelling story-telling and also its language parsing engines which allowed players to use not only simple commands ('Attack monster') but more complex ones with prepositions ('Attack the monster with the sword'). It was one of the most successful works of interactive fiction and its legacy is still alive today with many elements still being used in newer works\n",
    "\n",
    "### Plot\n",
    "***\n",
    "Zork is first and foremost an adventure game. The ultimate goal of the game is to collect all 19 different treasures and install them in a trophy case. To do so, the player must explore all areas of the game, including a sprawling underground dungeon.\n",
    "\n",
    "### Map\n",
    "***\n",
    "Below are two maps of the Zork world - above and below ground. As you can see it's a very large map with many different rooms and paths between them. Note that the player always starts at **West of House** on the above ground map.\n",
    "\n",
    "\n",
    "<img src='zork_map_1.gif'/> <img src='zork_map_2.gif'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prework\n",
    "***\n",
    "### Commands\n",
    "There are three types of commands used in Zork.\n",
    "\n",
    "1) Basic commands - commands to go a certain direction, commands to get info\n",
    "        - Go north, go south\n",
    "        - Look, check inventory\n",
    "2) Verb-Object commands - commands that consist of a verb and a noun or noun phrase\n",
    "        - Take key, open the door\n",
    "3) Verb-Object-Prep-Object commands - commands that consist of a verb and noun phrase followed by a preposition and second noun phrase\n",
    "        - Attack the monster with the sword, unlock the chest with the key\n",
    "    \n",
    "The objects in these commands can be gathered from the descriptions in-game. The verbs however need to be provide beforehand.\n",
    "\n",
    "### Verb dictionary\n",
    "\n",
    "To generate a list of possible verbs used in commands, info from the game file itself was gathered using ZTools (https://www.inform-fiction.org/zmachine/ztools.html).\n",
    "The text was processed using Matcher and POS from the <b>spacy</b> library to find all the possible verbs and verb phrases. This can be seen in the ZorkVerbs notebook.\n",
    "\n",
    "This list was then manually picked through to remove commands that would not influence gameplay (commands that save the game, change the text descriptions, etc.)\n",
    "\n",
    "Also, for the 2nd type of commands, the noun phrase was replaced with 'OBJ' and for the 3rd type of commands the first noun phrases were replaced with 'OBJ' and the second with 'DCT' to allow for easy substitution of nouns.\n",
    "\n",
    "The commands were then combined into a <i>commands</i> class and stored in a seperate script file (game_commands.py). The lists can be seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from game_commands import commands\n",
    "cmd = commands()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go north',\n",
       " 'go south',\n",
       " 'go west',\n",
       " 'go east',\n",
       " 'go northeast',\n",
       " 'go northwest',\n",
       " 'go southeast',\n",
       " 'go southwest',\n",
       " 'd',\n",
       " 'u']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Basic commands\n",
    "cmd.basic_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['open OBJ',\n",
       " 'get OBJ',\n",
       " 'set OBJ',\n",
       " 'hit OBJ',\n",
       " 'eat OBJ',\n",
       " 'put OBJ',\n",
       " 'cut OBJ',\n",
       " 'dig OBJ',\n",
       " 'ask OBJ',\n",
       " 'fix OBJ',\n",
       " 'make OBJ',\n",
       " 'wear OBJ',\n",
       " 'move OBJ',\n",
       " 'kick OBJ',\n",
       " 'kill OBJ',\n",
       " 'find OBJ',\n",
       " 'play OBJ',\n",
       " 'feel OBJ',\n",
       " 'hide OBJ',\n",
       " 'read OBJ',\n",
       " 'fill OBJ',\n",
       " 'flip OBJ',\n",
       " 'burn OBJ',\n",
       " 'pick OBJ',\n",
       " 'pour OBJ',\n",
       " 'pull OBJ',\n",
       " 'apply OBJ',\n",
       " 'leave OBJ',\n",
       " 'ask OBJ',\n",
       " 'break OBJ',\n",
       " 'enter OBJ',\n",
       " 'curse OBJ',\n",
       " 'shake OBJ',\n",
       " 'burn OBJ',\n",
       " 'inflate OBJ',\n",
       " 'brandish OBJ',\n",
       " 'donate OBJ',\n",
       " 'squeeze OBJ',\n",
       " 'attach OBJ',\n",
       " 'find OBJ',\n",
       " 'banish OBJ',\n",
       " 'read OBJ',\n",
       " 'enchant OBJ',\n",
       " 'feel OBJ',\n",
       " 'pour OBJ']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Verb-object commands\n",
    "cmd.command1_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pour OBJ on DCT',\n",
       " 'hide OBJ in DCT',\n",
       " 'pour OBJ in DCT',\n",
       " 'move OBJ in DCT',\n",
       " 'hide OBJ on DCT',\n",
       " 'flip OBJ for DCT',\n",
       " 'fix OBJ with DCT',\n",
       " 'spray OBJ on DCT',\n",
       " 'dig OBJ with DCT',\n",
       " 'cut OBJ with DCT',\n",
       " 'pick OBJ with DCT',\n",
       " 'squeeze OBJ on DCT',\n",
       " 'pour OBJ from DCT',\n",
       " 'fill OBJ with DCT',\n",
       " 'brandish OBJ at DCT',\n",
       " 'burn OBJ with DCT',\n",
       " 'flip OBJ with DCT',\n",
       " 'read OBJ with DCT',\n",
       " 'hide OBJ under DCT',\n",
       " 'carry OBJ from DCT',\n",
       " 'inflate OBJ with DCT',\n",
       " 'unlock OBJ with DCT',\n",
       " 'give OBJ to DCT',\n",
       " 'carry OBJ to DCT',\n",
       " 'spray OBJ with DCT']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Verb-object-prep-object commands\n",
    "cmd.command2_actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Command likelihood\n",
    "***\n",
    "When the nouns from the game's descriptions are substituted into the above commands, certain combinations might not make much sense. For example, if there is a door and a table in the environment, the command \"cut the door with the key\" would not make any sense.\n",
    "\n",
    "To help with this problem, walkthroughs and tutorials from other text-based games can be studied to have a way to determine the relevance and likelihood of different commands.\n",
    "\n",
    "This can all be found in the scrape_tutorials notebook but the basic idea is that tutorials and walkthroughs from two databases - https://www.ifarchive.org/indexes/if-archive/solutions/ and http://www.textfiles.com/adventure/ were scraped using __urllib__ and __BeautifulSoup__ to get text files containing relevant commands for these games.\n",
    "\n",
    "Those text files were then clean, preprocessed, and combined into one single file. The entire corpus was then ran through NLP using __spacy__.\n",
    "\n",
    "To determine likelihood of command phrases, a Word2Vec model was used to determine the similarity score.\n",
    "\n",
    "An example of this usage can be seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "f = open('tutorials_2.txt', 'r')\n",
    "tutorials = f.read()\n",
    "sentences = word_tokenize(tutorials)\n",
    "w2v = Word2Vec([sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020616088"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.similarity('open', 'table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97727084"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.similarity('open', 'chest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40543437"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.similarity(word_tokenize('attack chest with'), 'key').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4204148"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.similarity(word_tokenize('unlock chest with'), 'key').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game emulation\n",
    "***\n",
    "The majority of text-based games can be played using Z-Machine data files (.z3, .z4, .z5, .z8). To play games with this file format there are several emulators for different systems. For Windows one of the best emulators is __Frotz__ (https://github.com/DavidGriffith/frotz).\n",
    "\n",
    "Using __Popen__ in Python, a .exe version of the program can be used to play the Z-Machine games.\n",
    "\n",
    "In order to read the printout line by line without blocking the program a seperate thread is used and the lines can be read through a queue. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology \n",
    "***\n",
    "### Reinforcement learning\n",
    "***\n",
    "![](rl_diagram2.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For any general reinforcement learning network, there must be an __agent__ which, given a game __state__,  chooses an __action__ which then interacts with the __enviornment__. The new __state__ along with a corresponding __reward__ are then passed back to the __agent__ which then adjusts its weights for future decisions.\n",
    "\n",
    "### Environment\n",
    "For this project, the environment is the __Zork 1__ game which connects to Python via __Popen__ in order to be able to write new commands and read the lines given by the game.\n",
    "\n",
    "### State\n",
    "The state consists of both the _surroundings_ in the game as well as the _inventory_ of the player. The combination of these two will provide all necessary information including relevant objects to interact with.\n",
    "\n",
    "### Reward\n",
    "The reward should influence \"good\" behaviour while penalizing \"bad\" behaviour by the agent. There is already an in-game score given to the player when reaching certain areas or performing certain actions. However additional rewards can help to direct the agent more successfully. \n",
    "\n",
    "One of the most important parts of playing a text-based game is _exploration_. Any human player playing Zork would need to take part in exploration of the various areas and rooms to learn more about the game world and to find essential items.\n",
    "\n",
    "Another important part is finding, taking, and using _items_ in the game. For Zork especially, the main goal is to find and collect the various treasures so interacting with items should be rewarded. \n",
    "\n",
    "As far as negative rewards go, taking too many turns in a game usually is a bad thing as the goal should be to get to the end as quick as possible. Thus, a small negative reward can be given per each turn to help dissuade the agent from taking more turns than neccesary. \n",
    "\n",
    "Below are the different rewards.\n",
    "\n",
    "__negative_per_turn_reward__ : -1 points\n",
    "    - Each turn taken this reward will be added to the total reward for the round. This way, on turns where no other points were scored, the turn will be remembered as being non-productive. \n",
    "    \n",
    "__new_area_reward__ : 20 points\n",
    "    - Discovering a new area or room in the game should be rewarded in order to encourage exploration.\n",
    "    \n",
    "__moving_around_reward__: 0.5 points\n",
    "    - In order to prevent the agent from staying in one room too long, a small positive reward is given each time the agent moves from one area to another that has already been visited. This also helps to encourage the agent to return to an area it previously left when it had not yet completed all objectives in that area. Providing this reward instead of the new_area_reward when the agent revisits an area will prevent it from exploiting the reward system and hopping back and forth between rooms.\n",
    "\n",
    "__inventory_reward__ : 50 points\n",
    "    - If the agent picks up an item or uses an item, the in-game inventory will change. This will be rewarded with a large number of points as finding the treasures of the game ultimately is how the agent can win. \n",
    "    \n",
    "__inventory_not_new_reward__ : 0.5 points\n",
    "    - In order to prevent the agent taking advantage of the large inventory_reward, a much smaller reward will be given when an inventory change occurs that has already taken place. This will prevent exploitable situations in which the agent repeatedly picks up and then drops an item.\n",
    "\n",
    "__in_game_score_reward__ : 10 * in-game score\n",
    "    - Scoring points in the game is the best type of action the agent could take so it should be rewarded the greatest. Each time an in-game score is granted, a weight (initially set at 10) will be applied to it to show its significance to the agent. \n",
    "\n",
    "### Agent\n",
    "***\n",
    "The __agent__ consists of a neural network - more specifically a Deep-Q Network (referred to as DQN). The architecture of the model can be seen below.\n",
    "\n",
    "#### Input \n",
    "***\n",
    "The model takes in the _state_ and performed _action_ as seperate inputs. The inputs are preprocessed (removing special characters, converting to lower-case) and tokenized using a keras tokenizer with a vocabulary size of 1200. The tokens are then padded to ensure a consistent length of 50.\n",
    "#### Embedding\n",
    "***\n",
    "The _state_ and _action_ inputs are fed separately into a shared embedding layer with a dimension of 16. This layer is shared so that the vector for a word found in a _state_ will be the same vector if the word is in an _action_.\n",
    "#### LSTM\n",
    "***\n",
    "The _state_ and _action_ embeddings are then sent to a long short-term memory or LSTM layer. This layer hopes to capture some of the time based features in the _states_ and _actions_. For example, if the state is \"To the north lies a treasure chest and to the west there is a monster.\", the model should be able to capture the signficance of the order of the description. The LSTM layer uses a dimension of 32.\n",
    "#### Dense\n",
    "*** \n",
    "The model passes the output from the LSTM layers to separate dense layers of dimension 8. The activation function used at this layer is 'tanh'.\n",
    "#### Interaction\n",
    "***\n",
    "Lastly, to combine the dense _state_ and _action_ layers, a Dot layer is used to represent the condensed information of both inputs into a single value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-Learning\n",
    "***\n",
    "Q-learning allows an agent to make decisions based on future rewards. Instead of just picking the action that gives the highest reward for the current turn, Q-learning takes into account the future reward of the next state following an action as well.\n",
    "\n",
    "Below is the formula for the Q-function.\n",
    "\n",
    "<img src='q_function.png'/>\n",
    "\n",
    "The new calculated Q-value of a given state is found by using the old Q-value for that state and the sum of the current reward and the highest possible reward for the next state multiplied by a discount rate. The future reward is discounted because there is uncertainty in the predicted reward. Lastly, the sum of the current and future rewards is multiplied by a learning rate which slows down the learning process.\n",
    "\n",
    "In this project a learning rate of 0.1 and discount factor of 0.75 are used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals \n",
    "***\n",
    "The following shows different checkpoints of performance of the AI in this project. These can be used to measure and judge the performance of the AI.\n",
    "\n",
    "__Level 0__: Able to play the game at a basic level.\n",
    "    - The AI can process descriptions given by the game and generate likely actions from them.\n",
    "\n",
    "__Level 1__: Able to navigate across various areas and rooms.\n",
    "    - The AI can travel and discover new areas without getting stuck in one area for too long.\n",
    "\n",
    "__Level 2___: Able to complete mini-quests.\n",
    "    - The AI can complete simple tasks such as taking the egg from up in a tree in the forest and opening and enter the window into the house.\n",
    "\n",
    "__Level 3___: Able to access the underground.\n",
    "    - The AI can explore all areas above ground and find its way to the underground.\n",
    "\n",
    "__Level 4___: Able to collect treasures.\n",
    "    - The AI can find and gather more than one treasure without losing.\n",
    "\n",
    "__Level 5__: Able to beat the game.\n",
    "    - The AI can find all the treasures and win the game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation\n",
    "***\n",
    "Run for 1000 games, 250 turns to build vocabulary and find invalid actions\n",
    "Run for 50 games, 250 turns, batch size of 50\n",
    "Epsilon decay of 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
